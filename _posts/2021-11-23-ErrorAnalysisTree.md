---
layout: post
title:  "误差分析的骚操作"
author: willa
image: "https://img1.baidu.com/it/u=3829756115,105839803&fm=26&fmt=auto"
category: [日常整理]
featured: true
---

学习学习学习！



客户要求拎出来所有导致模型误差率超过10%的特征，老师给出的解决方案：

**将绝对误差率是否超过10%作为target_value，造一颗以recall_score为target_metric的树**。

因为想要了解特征对误差的真实影响，使用**train_test_split**, recall_score针对**验证集**。

其中透出了几层理解：

- 名义变量与其他变量的特征探索（EDA）：使用classification tree

- classification tree: 对数据进行切分，使得切分结果尽可能地pure

  切分的标准：

  - 数值变量/可合并的名义变量（factorize）：if feature<=value; else 
  - one-hot变量：if 当数值<=0.5; else (其实就是0或1的判断)
  - *↑以上的流程区别有针对python和R处理名义变量的意思*

- recall_score：**该案例更重视找到所有的误差超过10%的项目，想要尽量减小Type II Error.**

- 验证集oos metric的使用场景

  另外，主要使用名义变量，因为当某数值变量极差大且与其他变量高度有关时（比如y变量），极端情况下可以只通过切割该数值变量确定树

但是，这个解决方案的本质是**“boosting的一次迭代”，针对高误差样本的特征进行学习**。能够成功的**假设是：已有的模型没法有效学习现有特征的信息。**一个训练得较为robust的模型，其误差应该是随机的。

后来尝试的方法还有：

- v1：把feature_importance不为0的特征挑出来，看看仅根据这些特征筛选，能够覆盖多少高误差项目；
- v2：尝试原特征复杂模型，预测误差>10%的项目：
  - 结果导向：单独上线误差预警模型，使定价预测模型+误差预警模型的结果能覆盖90%的项目；
- v3：尝试结果解释向特征，依据新特征对项目误差进行解释：
  - 结果导向：在人为填报时进行预警，并交代在实行该预警的条件下，能捕捉多少误差项目
  - 与S4不同之处在于，这一轮（S5）误差分析目的在于支持预警，即找出一些特征，使满足这些特征的项目尽可能多地筛选出误差超过阈值的。而上一轮的目的是找出一些特征，使筛掉这些特征，模型能够尽量准确。





<br>

老师说这个case做完，所有误差分析相关的内容都遍历了，以后再多也不怕了（一次次失望后的平静.jpg）。所以稍微总结一下误差分析的几个阶段：

- S1. 高误差项目：验证输入数据的准确性，排除outlier

- S2. 误差可视化（如地图）：观察有无遗漏特征，如离外溢城市的距离

- S3. 误差和各特征的相关性：其实没做，但是说不定有用

- S4. 高误差特征：选择重点特征分析

  - 特征选择：主要是名义变量

    - 简单，客户好理解，方便筛选预警

  - 分析指标：MAPE、PPE

  - 分析模块

    - 各特征组的数量/占比（数量少的特征模型难以学习）

    - 各特征组的指标情况（找出表现较差的特征组，有高误差风险）

    - 各特征组误差分布情况与全市水平对比（tgi）（如果分布显著不同，则针对该特征组进行预警是有效的）

      *TODO：是不是可以直接做ANOVA test来着*

  - 结果导向

    - 试验：去掉不准确的特征，模型是否会更加准确（在有限制的模型下，能否提升准确率）
    - 试验：系统性缺失的特征，是否可以加入模型

- S5: 真·误差预警（如最上）

  

  <br>

纵观整个误差分析的过程，分为几重境界：

1. **数据输入层面**：验证数据的准确性（S1）
2. **模型特征层面**：通过控制、新增特征试图提升模型准确率；基于结果输出创造特征寻求解释
   - 已有特征：观察相关性，寻求解释（S2、S3、S4）
   - 遗漏特征：查漏（S2、S3、S4）
   - 模型结果相关特征：创造基于结果的解释向特征（S5 v2）
3. **误差的预测**：接受模型准确率难以提升的结局，预测“预测得不准的项目”（S5 v3）



也是被客户一步步逼到了现在呀，不过还是学到了很多东西。





